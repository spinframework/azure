apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-kwasm-annotate-nodes"
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      name: "{{ .Release.Name }}-kwasm-annotate-nodes"
    spec:
      serviceAccountName: "{{ .Release.Name }}-kwasm-annotate-sa"
      containers:
      - name: kubectl
        image: {{ printf "%s/%s:%s" .Values.global.azure.images.kubectl.registry .Values.global.azure.images.kubectl.image .Values.global.azure.images.kubectl.tag }}
        command: ["/bin/sh", "-c"]
        args:
          - |-
            echo "Annotating node with kwasm.sh/kwasm-node=false to reset installation of the shim for upgrade scenarios"
            kubectl annotate node --all kwasm.sh/kwasm-node=false --overwrite
            echo "Annotating node with kwasm.sh/kwasm-node=true to (re-)trigger installation of the shim"
            kubectl annotate node --all kwasm.sh/kwasm-node=true --overwrite
      restartPolicy: OnFailure
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "{{ .Release.Name }}-kwasm-annotate-sa"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: "{{ .Release.Name }}-kwasm-annotate-clusterrole"
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: "{{ .Release.Name }}-kwasm-annotate-clusterrolebinding"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: "{{ .Release.Name }}-kwasm-annotate-clusterrole"
subjects:
- kind: ServiceAccount
  name: "{{ .Release.Name }}-kwasm-annotate-sa"
  namespace: {{ .Release.Namespace }}